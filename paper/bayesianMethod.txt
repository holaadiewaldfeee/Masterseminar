Abstract:
We present a methodology for Bayesian analysis of software quality. We cast our research in the broader context of constructing a causal framework that can include process, product, and other diverse sources of information regarding fault introduction during the software development process. In this paper, we discuss the aspect of relating internal product metrics to external quality metrics. Specifically, we build a Bayesian network (BN) model to relate object-oriented software metrics to software fault content and fault proneness. Assuming that the relationship can be described as a generalized linear model, we derive parametric functional forms for the target node conditional distributions in the BN. These functional forms are shown to be able to represent linear, Poisson, and binomial logistic regression. The models are empirically evaluated using a public domain data set from a software subsystem. The results show that our approach produces statistically significant estimations and that our overall modeling method performs no worse than existing techniques.

The notion of a good quality software product, from the developer's viewpoint, is usually associated with the external quality metrics of 1) fault (or defect) content, i.e., the number of errors in a software artifact, 2) fault density, i.e., fault content per thousand lines of code, or 3) fault proneness, i.e., the probability that an artifact contains a fault. To guide the software verification and testing effort, several measures of software structural quality have been developed, e.g., the Chidamber-Kemerer (C-K) suite of metrics [1], [2]. These internal product metrics have been used in numerous models which relate them to the external quality metrics [3], [4], [5], [6], [7], [8], [9]. Owing to the belief that a high quality software process will produce a high quality software product [10], there are also some models in the literature which relate certain process measures to fault content [11], [12], [13]. The main idea in many of these existing approaches is to build a statistical model that relates the product or process metrics to the quality metrics.

Although one intuitively expects a high quality software development process to yield a high quality product, there is very little empirical evidence to support this belief. There is also sufficient variation in the development process so that faults enter the software from diverse sources. Many of these sources do not yet have established measures to support their inclusion in existing models for quality assessment, so they are subjectively qualified, e.g., conformance of the executed process to a process specification, quality of the development team, quality of the verification process. Consequently, the existing software quality assessment methods are insufficient for including such sources. Furthermore, there does not yet seem to be a standardized set of process measures that have been empirically validated as significant for software quality assessment. Besides these issues, Fenton et al. have identified various shortcomings with existing approaches and indicated the need for a causal model for quality assessment [14], [15], [16], [17].

Thus, there is a need for both 1) empirically validating the relationship of process measures with external quality metrics and 2) building a repertoire of statistical models which can incorporate existing product and process metrics, as well as other sources of evidence that may have been subjectively qualified.

Now, we briefly provide the context which motivates the work described in this paper. One of the broad goals of this work is to build a framework for quality assessment where we use not only the available process and product measurements, but also the evidence available from the diverse sources influencing fault introduction. Elsewhere [18], we have developed such a framework using Bayesian networks (BN) [19], as shown in Fig. 1. In short, our idea is to

separately consider product measurements as one set of factors that influence software quality,

separately consider the available process measurements and subjectively qualifiable process properties as another set of factors influencing quality,

redefine quality as the likelihood of observing properties of the software product, e.g., fault content, fault proneness, reliability, and

build a model capable of relating all the input variables to software quality.

In this paper, we mainly describe how Bayesian methods can be used for assessing quality (shown by the dotted box in Fig. 1). Specifically, we consider the C-K suite of metrics among the set of input variables and build a BN to relate them with both fault content and fault proneness. Assuming that the relationship can be modeled using a general linear model, we derive the structural and numeric specification for the BN. Our model can be thought of as a generalization of existing techniques for assessing software quality. Our model produces 1) a probability distribution of the estimated fault content per class in the system and 2) the conditional probability that a class contains a fault. Then, we empirically test our model using a data set from a real software subsystem. The results also show that our model produces these estimations at a statistically significant level.

We make the following contributions through this paper: First, we use a BN which relates software product metrics to fault content and fault proneness. Although there is some existing work in the literature that describes BN-based methods for defect content prediction [16], [17], [20], we believe that this is the first instance where a BN has been used for assessing defect proneness. Second, we assume that a general linear model relates the product metrics to quality; under certain assumptions, we show how multiple linear regression, Poisson regression, and logistic regression can be represented as a BN. This is the underlying functional form used to numerically specify the BN. Third, we use an entirely Bayesian approach for data analysis: Specifically, we use both Bayesian linear regression and Bayesian Poisson regression in fault content analysis. We find, surprisingly, that the linear model is better at describing the data than the Poisson model. However, since our analysis is based on only one data set, we believe that the study should be replicated on different sets of data to generalize our findings. Fourth, we add to the body of empirical knowledge about the relationship between certain measures for object-oriented software and fault content.



